# -*- coding: utf-8 -*-
"""spamweb.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jtBsQjyQ5D6fIb-fgI2fQv47aY5Y-RsT

# URL spam detector data from https://www.kaggle.com/datasets/shivamb/spam-url-prediction
"""

## imports and dataset
import pandas as pd
from google.colab import drive

# Mount Google Drive
drive.mount('/content/drive')

df = pd.read_csv('/content/drive/My Drive/spamweb/url_spam_classification.csv')
df.head()

import matplotlib.pyplot as plt
plt.pie(df['is_spam'].value_counts(), labels = ['legit','fake'], autopct = '%0.2f')
plt.show()

df['len_url'] = df['url'].apply(lambda x : len(x))
df['contains_subscribe'] = df['url'].apply(lambda x : 1 if "subscribe" in x else 0)
df['contains_hash'] = df['url'].apply(lambda x : 1 if "#" in x else 0)
df['num_digits'] = df['url'].apply(lambda x : len("".join(_ for _ in x if _.isdigit())) )
df['non_https'] = df['url'].apply(lambda x : 1 if "https" in x else 0)
df['num_words'] = df['url'].apply(lambda x : len(x.split("/")))
df.head()

import plotly.express as px
fig = px.histogram(df, x="len_url", color="is_spam")
fig.update_layout(title = "URLs length by Spam / Non Spam", xaxis_title="URL Length", yaxis_title = "", plot_bgcolor="#fff", showlegend = False)
fig.show()

fig = px.histogram(df, x="num_digits", color="is_spam")
fig.update_layout(title = "URLs Digit Counts by Spam / Non Spam", xaxis_title="Number of Digits", yaxis_title = "", plot_bgcolor="#fff", showlegend = False)
fig.show()

fig = px.histogram(df, x="num_words", color="is_spam")
fig.update_layout(title = "URLs Number of Words by Spam / Non Spam", xaxis_title="Num Words", yaxis_title = "", plot_bgcolor="#fff", showlegend = False)
fig.show()

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.pipeline import Pipeline
import matplotlib.pyplot as plt
from sklearn.metrics import roc_auc_score, roc_curve

target = 'is_spam'
features = [f for f in df.columns if f not in ["url", target]]
X_train, X_test, y_train, y_test = train_test_split(df[features], df[target], test_size=0.2, random_state=0)

sc = MinMaxScaler()
clf = LogisticRegression()
pipe_lr = Pipeline([('scaler', sc), ('clf', clf)])
pipe_lr.fit(X_train, y_train)

test_probas = pipe_lr.predict_proba(X_test)[:,1]
plt.figure(figsize=(10,8))
fpr, tpr, tresholds = roc_curve(y_test, test_probas)
plt.plot(fpr, tpr)
plt.title('ROC Curve')
plt.xlabel('FPR')
plt.ylabel('TPR')

print('ROC-AUC-score: ', roc_auc_score(y_test, test_probas))

import numpy as np
from skl2onnx import to_onnx

# Convert the entire pipeline to ONNX
onx = to_onnx(pipe_lr, X_train[:1].astype(np.float32), target_opset=12)

# Save the ONNX model
with open("spamweb.onnx", "wb") as f:
    f.write(onx.SerializeToString())

import os
print(os.listdir('/content/'))

!pip install skl2onnx

import numpy as np
from onnxruntime import InferenceSession

# Load the ONNX model
with open("spamweb.onnx", "rb") as f:
    onx = f.read()
sess = InferenceSession(onx, providers=["CPUExecutionProvider"])

# Get input names from the model
input_names = [inp.name for inp in sess.get_inputs()]
print("Model input names:", input_names)

# Prepare input as a dictionary with feature names
input_dict = {}
for name in input_names:
    # Assuming X_test is a DataFrame with the same column names as the model inputs
    input_dict[name] = X_test[name].astype(np.float32).values.reshape(-1, 1)

# Run prediction
outputs = sess.run(None, input_dict)
pred_ort = outputs[0]  # Label output
prob_ort = outputs[1]  # Probability output

!pip install onnxruntime

import numpy as np
from onnxruntime import InferenceSession

with open("spamweb.onnx", "rb") as f:
    onx = f.read()
sess = InferenceSession(onx, providers=["CPUExecutionProvider"])

input_names = [inp.name for inp in sess.get_inputs()]
print("Model input names:", input_names)

x = "gov.uk"
a = len(x)
b = 1 if "subscribe" in x else 0
c = 1 if "#" in x else 0
d = sum(1 for i in x if i.isnumeric())
e = 0 if "https" in x else 1
f = len(x.split("/"))

input_dict = {
        "len_url": np.array([[a]], dtype=np.float32),
        "contains_subscribe": np.array([[b]], dtype=np.float32),
        "contains_hash": np.array([[c]], dtype=np.float32),
        "num_digits": np.array([[d]], dtype=np.float32),
        "non_https": np.array([[e]], dtype=np.float32),
        "num_words": np.array([[f]], dtype=np.float32),
}

    # Predict
pred_ort = sess.run(None, input_dict)
print(pred_ort)